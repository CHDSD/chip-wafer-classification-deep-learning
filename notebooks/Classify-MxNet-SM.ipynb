{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook continues from the _DataPrep_ notebook and tries to use a CNN based on ResNet in the MxNet framework for classification.\n",
    "\n",
    "## Data Set\n",
    "\n",
    "[Qingyi](https://www.kaggle.com/qingyi). (February 2018). WM-811K wafer map, Version 1. Retrieved January 2018 from https://www.kaggle.com/qingyi/wm811k-wafer-map/downloads/wm811k-wafer-map.zip/1.\n",
    "\n",
    "## License\n",
    "\n",
    "Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo\n",
    "from mxnet.gluon import utils as gutils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'training': 's3://chip-wafer/data/train_rec', 'validation': 's3://chip-wafer/data/valid_rec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "learning_rate = 0.001\n",
    "wd = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet(\"classify_mxnet.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.p3.2xlarge\",\n",
    "          framework_version=\"1.2.1\",\n",
    "          py_version=\"py3\",\n",
    "          hyperparameters={'batch_size': batch_size,\n",
    "                         'epochs': epochs,\n",
    "                         'learning_rate': learning_rate,\n",
    "                         'momentum': 0.9, \n",
    "                         'wd': wd,\n",
    "                         'log_interval': 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = gdata.vision.ImageFolderDataset('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_r = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import io, json\n",
    "import itertools\n",
    "def evaluate_metrics(dataset):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    preds = []\n",
    "    trues = []\n",
    "    cnt = 0\n",
    "    cnt_step = 500\n",
    "    for item in dataset.items:\n",
    "        img_path = item[0]\n",
    "        label = item[1]    \n",
    "        with io.FileIO(img_path, 'r') as imageBuffer:\n",
    "            response = sagemaker_r.invoke_endpoint(\n",
    "                              EndpointName = 'sagemaker-mxnet-2019-04-22-23-47-12-458',\n",
    "                              Body=imageBuffer.read(),\n",
    "                              ContentType='image/png',\n",
    "                              Accept='application/json'\n",
    "                          )\n",
    "            res_json = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    \n",
    "        \n",
    "        trues.append(label)\n",
    "        preds.append(int(res_json))\n",
    "        \n",
    "        if cnt % cnt_step == 0:\n",
    "            print(\"Working on \" + str(cnt))\n",
    "        cnt = cnt + 1\n",
    "    return trues, preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues, preds = evaluate_metrics(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(trues, preds)))\n",
    "print(\"Weighted F1 Score: {0}\".format(f1_score(trues, preds, average='weighted')))\n",
    "print(\"Weighted F-beta: {0}\".format(fbeta_score(trues, preds, average='weighted', beta=1.0)))\n",
    "print(\"Macro F1 Score: {0}\".format(f1_score(trues, preds, average='macro')))\n",
    "print(\"Macro F-beta: {0}\".format(fbeta_score(trues, preds, average='macro', beta=1.0)))\n",
    "print(\"Micro F1 Score: {0}\".format(f1_score(trues, preds, average='micro')))\n",
    "print(\"Micro F-beta: {0}\".format(fbeta_score(trues, preds, average='micro', beta=1.0)))\n",
    "print(classification_report(trues, preds, target_names=test_imgs.synsets))\n",
    "cm = confusion_matrix(trues, preds)\n",
    "plot_confusion_matrix(cm, test_imgs.synsets, normalize=False)\n",
    "plot_confusion_matrix(cm, test_imgs.synsets, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
